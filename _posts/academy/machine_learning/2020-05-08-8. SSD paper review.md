---
title: 8. SSD 논문 리뷰
excerpt: "논문명: SSD: Single Shot MultiBox Detector"
categories: 
 - Machine Learning
tags: 
 - SSD
 - Single Shot MultiBox Detector
 - 논문 리뷰

#excerpt: 

header:
 teaser: https://github.com/pierluigiferrari/ssd_keras/raw/master/examples/trained_ssd300_pascalVOC2007_test_pred_04_no_gt.png
 overlay_image: https://github.com/pierluigiferrari/ssd_keras/raw/master/examples/trained_ssd300_pascalVOC2007_test_pred_04_no_gt.png
 overlay_filter: 0.5
 #caption: Photo by Luca Bravo on Unsplash

icon: fa-github
---

논문 링크 : <https://arxiv.org/pdf/1512.02325.pdf>

object detection 분야에 RCNN, MobileNet, SSD, YOLO 등 많은 모델이 있다. 이번 글은 SSD 모델에 대해 살펴보겠다.

아래는 detection 분야의 네트워크들의 논문 리스트이다.

[![나타낼 수 없음](https://github.com/hoya012/deep_learning_object_detection/raw/master/assets/deep_learning_object_detection_history.PNG)](https://github.com/hoya012/deep_learning_object_detection/raw/master/assets/deep_learning_object_detection_history.PNG)

빨간 색은 지금까지의 핵심적인 논문들을 나타낸 것이다.

## Abstract

SSD는 본 논문에 다음과 같이 묘사한다.

> Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location.

bbox의 출력 공간을 각 feature map 위치마다 다른 종횡비 및 스케일을 갖는 default box들의 세트로 나눈다.



VOC2007 set에서의 성능은 다음과 같다.

ssd300: 300x300 input, 74.3% mAP 검출 정확도, 59 fps on a Nvidia titan X

ssd512: 512x512 input, 76.9% mAP 검출 정확도

---

## 1. Introduction

object detection 분야에서는 hypothesize bounding boxes, re-sample pixels or features for each box, and apply a high-quality classifier등 다양한 접근법을 사용중이다.

이 논문은 bounding box 예측을 위한 pixel이나 feature들의 re-sample을 하지 않은 최초의 deep network 기반 object detector라고 자신있게 말한다. 또한 당시 object detection 분야에서 좋은 성능을 보였던 net들이 VOC2007 기준 Faster R-CNN의 경우  검출 정확도 73.2% mAP에서 7fps, YOLO의 경우 45fps였지만 63.4% mAP로 성능이 더 낮았다. 반면 SSD는 74.3% mAP 로 Faster R-CNN과 비슷한 검출 정확도를 나타내면서도 59 fps로 빠른 속도를 얻으며 high-accuracy & fast speed로 significant improvement되었다고 본문에서 이야기 한다.

본문에서 본 논문을 다음과 같이 요약한다.

- SSD 소개: SSD는 이전의 Fater R-CNN, YOLO보다 성능&속도 전체적인 면에서 상당히 개선되었다.
- SSD의 핵심: feature map에 적용된 작은 convolutional filter를 사용하여 고정된 default bounding box의 category score 및 box offset을 예측
- 정확도 향상을 위한 기법: feature map의 스케일에 따른 다른 예측 사용, 예측을 종횡비로 명시적 분리
- 디자인에 따른 이점: simple end-to-end training, high accuracy, low resolution images에서도 성능 좋음, speed vs. accuracy trade-off 향상
- 실험: PASCAL, VOC, COO, ILSVRC 등 다양한 크기에 대한 속도 및 성능


## 2. The Single Shot Detector (SSD)

2.1절에서는 detection을 위해 제안한 SSD framework에 대해, 2.2절에서는 training 방법론에 대해 기술한다. 3장에서는 dataset에 따른 model 및 실험 결과를 설명한다.

### 2.1. Model

SSD는 feed-forward convolutional network를 기본으로 하며 고정 크기의 bounding box 및 이러한 box에 object class 인스턴스를 나타내는 score를 생성한다. 최종 detection을 위해 non-maximum suppression 단계가 뒤에 구성된다.

[![나타낼 수 없음](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/assets/SSDModel.png)](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/assets/SSDModel.png)

저해상도에서도 잘 동작하므로 300x300 크기의 이미지를 입력으로 초기 layer는 image classification에서 성능이 좋은 VGG-16을 base로 conv5_3까지 사용한다. 이 base network를 통과하면 300x300x3의 입력이 38x38x512로 바뀐다.

이후 다음의 몇가지 주요 key feature들을 추가한다.

**Multi-scale feature maps for detection**

한장의 사진으로부터 여러 크기의 물체 검출을 위해 Multi-scale feature maps을 위해 convolutional feature layer들을 추가한다.

이 layer들을 통해 크기를 점진적으로 줄여(38x38, 19x19, 10x10, 5x5, 3x3, 1x1 등) multi-scale detection 예측을 가능하게 한다. YOLO는 7x7의 single-scale feature map을 사용하였지만 SSD는 6개의 multi-scale을 사용한다.

**Convolutional predictors for detection**

p 채널의 $$ m \times n $$ 크기를 갖는 feature map은, 각 위치 마다 $$3 \times 3 \times p$$ kernel을 적용할 수 있으며, 각 kernel(filter) 은 category나 bounding box offset score를 만든다. (YOLO는 FCL로 연결, 여기서 속도단축이 큼) bounding box offset이란 각 cell(feature map 한 칸)을 기준으로 한 상대적 위치와 박스의 크기를 의미한다.

**Default boxes and aspect ratios**

위에서 bounding box offset output value를 위해 필요한 정보는(cx, cy, width, height)로 4개이며 $$ m \times n $$ 크기를 갖는 feature map에 대한 출력은 다음과 같다.

$$(c+4)\times k \times m \times n$$

- $$k$$: 위치의 수
- $$c$$: class score

default box들은 아래 그림 1과 같다.

[![나타낼 수 없음](https://camo.githubusercontent.com/1fcabb852f473582d3bfa2fb38be156fc45f3b73/68747470733a2f2f66696c65732e736c61636b2e636f6d2f66696c65732d7072692f54314a3753434855372d4644314b3247364e512f666967312e706e673f7075625f7365637265743d38316430386537353336)](https://camo.githubusercontent.com/1fcabb852f473582d3bfa2fb38be156fc45f3b73/68747470733a2f2f66696c65732e736c61636b2e636f6d2f66696c65732d7072692f54314a3753434855372d4644314b3247364e512f666967312e706e673f7075625f7365637265743d38316430386537353336)

Faster R-CNN의 anchor box와 비슷하지만 하나의 크기에 대한 feature map이 아닌 SSD는 다양한 크기의 feature map을 사용한다.

이 절에서 자세히 설명되진 않았지만 실제 SSD에서는 feature map을 $$ m \times n $$의 가변적인 크기를 사용하지 않고 위에 언급했던 미리 정의된 크기를 정의하고 aspect ratio의 개념을 도입하여 ratio에 따라 효율적으로 나타낸다.

### 2.2. Training

> The key difference between training SSD and training a typical detector that uses region proposals, is that ground truth information needs to be assigned to specific outputs in
the fixed set of detector outputs.

직역하면 의미가 어렵지만 의역하면

SSD와 전형적인 detector의 주요 차이점은 GT 정보를 multi-scale feature map에 맞게 변환 적용해야 한다는 의미같다.

또한 training에는 detection을 위해 default box와 scale의 set에 대한 것과 hard negative mining, data augmentation 전략도 포함된다.

**Matching strategy**

어떤 default box가 GT detection에 일치하는지 판단하고 이에 따라 network를 train한다. 각 GT box는 각 default box에 대해 location, aspect ratio, scale에 따라 선택한다.

이 때 일치여부를 jaccard overlap를 통해 하는데 본문에서 얘기하지 않았지만 이는 IoU와 같은 것으로 0.5의 threshold를 사용해 넘으면 일치한다고 가정한다. IoU가 가장 큰 하나를 선택하는 방법에 비해 이점은 threshold를 넘는 상자를 모두 선택하는 이유는 높은 정확도를 가진 상자를 한꺼번에 여러번 학습시킴으로써 높은 학습율을 얻는다.

**Training objective**

SSD training 목표는 MultiBox objective로 부터 파생되었지만 multiple objective category를 위해 확장된다. $$i$$번째 default box, category p의 $$j$$번째 GT box에 대한 indicator를 $$x^p_{ij}=\{1,0\}$$라고 하면 위의 matching strategy로부터 다음을 얻을 수 있다.

$$\sum_{i}x^p_{ij} \geq 1$$

또한 objective loss는 confidence loss와 localization loss의 weighted sum으로 다음과 같다.

$$L(x,e,l,g) = \frac{1}{N}(L_{conf}(x,c) + \alpha L_{loc}(x,l,g))$$

- N: number of matched default boxes
- $$L_{conf}$$: confidence loss
- $$L_{loc}$$: localization loss

만약 $$N==0$$ 이라면 loss는 0으로 한다.

localization loss는 예측된 box와 GT box 파라미터들 사이의 Smooth L1 loss로 다음과 같다.

$$
L_{loc}(x,l,g)=\sum_{i \in Pos}^N \sum_{m \in \{cx,cy,w,h\}} x_{ij}^k smooth_{L1}(l_i^m-\hat{g}_j^m) \\

\hat{g}_j^{cx}=(g_j^{cx}-d_i^{cx})/d_i^w
\quad\quad\quad\quad
\hat{g}_j^{cy}=(g_j^{cy}-d_i^{cy})/d_i^h \\

\hat{g}_j^{w}=log(\frac{g_j^{w}}{d_i^{w}})
\quad\quad\quad\quad
\hat{g}_j^{h}=log(\frac{g_j^{h}}{d_i^{h}})
$$

위에서 언급했듯이 Faster R-CNN과 비슷하게 offset을 (cx, cy, width, height)로 나타낸다.

confidence loss는 multiple classes confidences에 대한 softmax loss로 다음과 같다.

$$
L_{conf}(x,c)=-\sum_{i \in Pos}^N x_{ij}^p log(\hat{c}_i^p)-\sum_{i \in Neg} log(\hat{c}_i^0)
\quad
\text{Where}
\quad
\hat{c}_i^p=\frac{exp(c_i^p)}{\sum_p exp(c_i^p)}
$$

여기서 $$\alpha$$는 실험으로 1로 설정되었다.

**Choosing scales and aspect ratios for default boxes**

다른 object scale에 대해 일부의 detection network들은 다른 크기로 이미지를 처리하고 나중에 결과를 결합하는 방법을 사용한다. 그러나 SSD에서는 single network에서 여러 layer로 부터 feature map을 활용하여 동일한 효과를 만들며, 모든 object scale에 parameter를 공유한다.

FCN등의 이전연구에서는 lower layer의 feature map을 사용하면 입력 object의 detail 더 새밀하게 가져오므로 semantic segmentation의 quality를 향상시킬 수 있음을 보였다. 이를 SSD에 적용해 feature map으로부터 pool된 global context 추가하여 더욱 smooth한 segmentation 결과를 얻었다.

또한 일반적으로 network에서 다른 level의 feature map은 다른 크기의 receptive field를 갖지만 SSD framework에서 default box들은 각 layer의 실제 receptive field와 일치하지 않아도 된다. 각 feature map이 각 object의 scale에 대응되는 것으로 학습되도록 default box의 타일 분할을 설계하였다.

각 feature map의 default box scale은 다음과 같이 계산된다.

$$
S_k = S_\text{min} + \frac{s_\text{max}-s_\text{min}}{m-1} (k-1), \quad k \in [1, m] \\
a_r \in \{ 1,2,3,\frac{1}{2},\frac{1}{3} \} \\
W_k^a = S_k \sqrt {a_r} \\
h_k^a = S_k /\sqrt {a_r} \\
bc=(\frac{i+0.5}{|f_k|},\frac{j+0.5}{|f_k|}), \quad i,j \in [0, |f_k|]
$$

- S: $$S_\text{min}=0.2, S_\text{max}=0.9$$
- $$a_r$$: aspect ratio
- $$W_k^a$$: width
- $$H_k^a$$: height
- $$bc$$: default box center
- $$|f_k|$$: size of the $$k$$-th square feature map
- $$a_r==1$$일 때: $$s_k^{'} = \sqrt{s_k s_{k+1}}$$를 default box에 추가

결과로 feature map당 6개의 default box가 생성된다.

SSD 실험팀은 특정 set에 적합하도록 설계하였기 때문에 최적의 설계는 open question으로 남겨뒀다.

**Hard negative mining**

matching을 돌리고 나면 positive에 비해 너무나도 많은 negative sample이 나오게 된다. 이 sample을 모두 훈련시키면, sample을 불균형으로 제대로 학습이 되지 않는다고 한다. 따라서 모든 matching 상자들 중, 점수가 상대적으로 높은 것들을 negative로 학습시킨다. 논문의 저자는 negative의 개수를 최대 positive의 3배 까지만 학습을 시키는 것이 최적화가 빨라지고 훈련이 좀 더 안정화된다고 주장한다.

**Data augmentation**

입력을 전부 날 것으로 넣으면, 물체나 환경 변화에 대처를 잘 못하게 된다. 따라서 입력 이미지를 다음 세 개 중에 랜덤으로 선택해서 집어넣어, 좀 더 Robust 하게 훈련을 시킨다.

- 입력 이미지를 그대로 넣기
- 최소 Jaccard overlap(IoU)이 0.1, 0.3, 0.5, 0.7, 0.9 인 샘플 패치를 넣기
- 랜덤으로 정해진 패치를 넣기

## 3. Experimental Results

### 3.1. PASCAL VOC2007

[![나타낼 수 없음](https://files.slack.com/files-pri/T1J7SCHU7-FD1M4T059/table1.png?pub_secret=087d18839f)](https://files.slack.com/files-pri/T1J7SCHU7-FD1M4T059/table1.png?pub_secret=087d18839f)

### 3.2. Model analysis

**Data augmentation is crucial**

[![나타낼 수 없음](https://files.slack.com/files-pri/T1J7SCHU7-FD1H6MZHA/table2.png?pub_secret=fac9773b96)](https://files.slack.com/files-pri/T1J7SCHU7-FD1H6MZHA/table2.png?pub_secret=fac9773b96)

**More default box shapes is better**

**Atrous is faster**

**Multiple output layers at different resolutions is better**

### 3.3. PASCAL VOC2012

[![나타낼 수 없음](https://files.slack.com/files-pri/T1J7SCHU7-FD158UY6M/table4.png?pub_secret=37617a9e8a)](https://files.slack.com/files-pri/T1J7SCHU7-FD158UY6M/table4.png?pub_secret=37617a9e8a)

### 3.4. COCO

[![나타낼 수 없음](https://files.slack.com/files-pri/T1J7SCHU7-FD1TXRB7F/table5.png?pub_secret=f36520b09d)](https://files.slack.com/files-pri/T1J7SCHU7-FD1TXRB7F/table5.png?pub_secret=f36520b09d)

### 3.5. Preliminary ILSVRC results

결론 SSD는 high quality real-time detector이다.

### 3.6. Data Augmentation for Small Object Accuracy

[![나타낼 수 없음](https://files.slack.com/files-pri/T1J7SCHU7-FD2047QLV/a.png?pub_secret=83ce01f7c2)](https://files.slack.com/files-pri/T1J7SCHU7-FD2047QLV/a.png?pub_secret=83ce01f7c2)

### 3.7. Inference time

[![나타낼 수 없음](https://files.slack.com/files-pri/T1J7SCHU7-FD2Q612QP/table7.png?pub_secret=cdf7a52133)](https://files.slack.com/files-pri/T1J7SCHU7-FD2Q612QP/table7.png?pub_secret=cdf7a52133)

## 4. Related Work

- DPM(Deformable Part Model)
- SS(Selective Search)
- R-CNN, Fast R-CNN, Faster R-CNN
- SPPnet
- MultiBox
- YOLO

**Reference**

- [TAEU's blog](https://taeu.github.io/paper/deeplearning-paper-ssd/)
- [junjiwon's blog](https://junjiwon1031.github.io/2017/09/08/Single-Shot-Multibox-Detector.html)
- [pierluigiferrari's github](https://github.com/pierluigiferrari/ssd_keras)