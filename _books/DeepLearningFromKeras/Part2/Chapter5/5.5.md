---
title: 5.5 요약
---


## 5.5  요약

•  컨브넷은 시각적인 분류 문제를 다루는 데 최상의 도구입니다.

•  컨브넷은 우리가 보는 세상을 표현하기 위한 패턴의 계층 구조와 개념을 학습합니다.

•  학습된 표현은 쉽게 분석할 수 있습니다. 컨브넷은 블랙 박스가 아닙니다!

•  이미지 분류 문제를 풀기 위해 자신만의 컨브넷을 처음부터 훈련시킬 수 있습니다.

•  과대적합을 줄이기 위해 데이터를 증식하는 방법을 배웠습니다.

•  사전 훈련된 컨브넷을 사용하여 특성 추출과 미세 조정하는 방법을 배웠습니다.

•  클래스 활성화 히트맵을 포함하여 컨브넷이 학습한 필터를 시각화할 수 있습니다.

[1](Section0501.html#footnote-05-1-backlink)  역주  이 책에서는 가능하면 ‘densely connected’를 ‘밀집 연결’로 번역하지 않고 동일한 뜻으로 더 널리 사용되는 ‘완전 연결(fully connected)’로 번역합니다.

[2](Section0501.html#footnote-05-2-backlink)  역주  모델의  summary()  메서드는 신경망 구조를 일목요연하게 출력해 줍니다. 출력의 시작 부분이 신경망 입력에 가까운 하위 층이고 끝부분이 신경망 출력에 가까운 상위 층입니다. 이 메서드는  keras.utils.print_summary()  함수를 사용합니다.  keras.utils.print_summary(model)처럼 쓰면 동일한 출력을 얻을 수 있습니다.

[3](Section0501.html#footnote-05-3-backlink)  역주  4장에서 배웠듯이 모델을 비교하려면 검증 세트를 사용해야 합니다. 책에서는 간단한 예제를 만들기 위해서 테스트 세트를 검증 세트처럼 사용합니다.

[4](Section0501.html#footnote-05-4-backlink)  역주  1장과 2장에서는 신경망의 층을 데이터를 처리하는 필터로 비유했습니다. 여기서 필터는 합성곱 층에서 사용하는 모델 파라미터를 의미합니다.  Conv2D의 첫 번째 매개변수(필터 또는 채널 수)가 출력 특성 맵의 깊이 차원을 결정합니다.

[5](Section0501.html#footnote-05-5-backlink)  역주  필터 하나의 크기는  (patch_height, patch_width, input_depth)입니다. 첫 번째 합성곱은  (3, 3, 1)  크기의 필터를 32개 적용하고, 두 번째 합성곱은  (3, 3, 32)  크기의 필터를 64개 적용합니다.

[6](Section0501.html#footnote-05-6-backlink)  역주  여기서 합성곱 커널은 합성곱 층의 필터를 하나의 행렬로 합친 것을 말합니다. 첫 번째 합성곱 층의 커널 크기는  (3, 3, 1, 32)이고, 두 번째 합성곱 층의 커널 크기는  (3, 3, 32, 64)입니다.

[7](Section0501.html#footnote-05-7-backlink)  역주  이 그림에서 출력의 깊이가 3이므로 패치마다  (3, 3, 2)  크기의 필터가 3개 적용된 것입니다. 다르게 말하면  (3, 3, 2, 3)  크기의 커널과 점곱한 것입니다.

[8](Section0501.html#footnote-05-8-backlink)  역주  추가되는 행과 열은 0으로 채워지기 때문에 제로 패딩(zero padding)이라고도 부릅니다.

[9](Section0501.html#footnote-05-9-backlink)  역주  스트라이드와 패딩에 대한 좀 더 자세한 설명과 시뮬레이션은 제 블로그의 ‘딥러닝을 위한 콘볼루션 계산 가이드([https://goo.gl/qvNTyu](https://goo.gl/qvNTyu))’를 참고하세요.

[10](Section0501.html#footnote-05-10-backlink)  역주  7×7 크기의 입력을 3×3 윈도우로 합성곱하면 5×5로 줄어들고, 다시 한 번 합성곱하면 3×3으로 줄어듭니다. 바꾸어 말하면 두 번째 합성곱을 통과한 특성 맵의 3×3 크기에는 입력에 있는 7×7 크기의 정보만 담겨 있습니다.

[11](Section0502.html#footnote-05-11-backlink)  역주  책의 깃허브에는 캐글에서 내려받은 train.zip 파일의 압축을 풀어 예제에 필요한 데이터를 ‘datasets/cats_and_dogs/train’ 폴더 아래에 넣어 놓았으므로 별도로 내려받을 필요가 없습니다.

[12](Section0502.html#footnote-05-12-backlink)  역주  사실 캐글 사이트에는 별도의 테스트 데이터가 따로 있습니다. 이 테스트 데이터에는 타깃 레이블이 없고 참가자들은 테스트 데이터의 예측 레이블을 업로드하여 순위를 겨루게 됩니다. 이 책에서는 완전한 예제를 구성하기 위해 훈련 데이터로부터 훈련, 검증, 테스트 세트를 만듭니다.

[13](Section0502.html#footnote-05-13-backlink)  역주  코드 5-7에 사용된  ImageDataGenerator  클래스의  flow_from_directory()  메서드는 서브 디렉터리의 순서대로 레이블을 할당합니다. 여기에서는 ‘datasets/cats_and_dogs_small/train’ 디렉터리 아래 ‘cats’와 ‘dogs’가 순서대로 0, 1 레이블을 가집니다. 즉 ‘dogs’가 타깃 클래스가 되므로 최종 시그모이드의 출력은 강아지 이미지일 확률을 인코딩합니다.  classes  매개변수를 사용하면 디렉터리에 레이블이 할당되는 순서를 바꿀 수 있습니다.  flow_from_directory(classes=['dogs', 'cats'])처럼 하면 ‘cats’가 타깃 클래스 1이 됩니다.

[14](Section0502.html#footnote-05-14-backlink)  역주  keras.preprocessing  아래의  image,  sequence,  text  모듈은 Keras-Preprocessing 패키지의 알리아스(alias)입니다. 이 패키지는 케라스와 함께 자동으로 설치됩니다.

[15](Section0502.html#footnote-05-15-backlink)  역주  class_mode  매개변수의 값은 다중 분류일 때는 ‘categorical’ 또는 ‘sparse’, 이진 분류일 때는 ‘binary’를 사용합니다. ‘categorical’은 원-핫 인코딩된 2차원 배열을 반환하고 ‘sparse’는 정수 레이블을 담은 1차원 배열을 반환합니다. ‘binary’는 0 또는 1로 채워진 1차원 배열을 반환합니다. 마지막으로 오토인코더처럼 입력을 타깃으로 하는 경우에는  class_mode를 ‘input’이라고 지정합니다.  class_mode의 기본값은 ‘categorical’입니다.

[16](Section0502.html#footnote-05-16-backlink)  역주  파이썬의 제너레이터는 특수한 반복자이며  yield 문을 사용하여 만든 경우를 제너레이터 함수, 소괄호와 리스트 내포 구문을 사용하는 경우를 제너레이터 표현식이라고 부릅니다. 파이썬의  itertools  아래에는 간단한 제너레이터를 대신할 수 있는 다양한 반복자가 준비되어 있습니다.  count  반복자를 사용하면 본문의  generator()  함수를  count(1)로 간단하게 바꿀 수 있습니다. 리스트와 달리 반복자와 제너레이터는 전체 항목을 미리 만들지 않으므로 메모리 효율적입니다. 제너레이터에 관한 좀 더 자세한 설명은 제 블로그를 참고하세요([https://bit.ly/2KGrQxk](https://bit.ly/2KGrQxk)).

[17](Section0502.html#footnote-05-17-backlink)  역주  코드 5-7에서  validation_generator의 배치가 20개로 지정되었으므로 전체 검증 데이터(1,000개)를 사용하려면 validation_steps를 50으로 설정합니다.

[18](Section0502.html#footnote-05-18-backlink)  역주  회전 각도의 범위는  -rotation_range ~ +rotation_range가 됩니다.

[19](Section0502.html#footnote-05-19-backlink)  역주  width_shift_range와  height_shift_range가 1보다 큰 실수이거나 정수일 때는 픽셀 값으로 간주됩니다. 실수가 입력되면 이동 범위는  [-width_shift_range, +width_shift_range)가 됩니다. 하나의 정수가 입력되면 이동 범위는  (-width_shift_range, +width_shift_range)가 됩니다. 정수 리스트가 입력되면 하나를 랜덤하게 선택하고 다시 랜덤하게 음수 또는 양수로 바꾼 후 이동시킵니다.

[20](Section0502.html#footnote-05-20-backlink)  역주  전단 변환은  rotation_range로 회전할 때 y축 방향으로 각도를 증가시켜 이미지를 변형시킵니다.

[21](Section0502.html#footnote-05-21-backlink)  역주  실수가 입력되면  1-zoom_range ~ 1+zoom_range  사이로 확대 또는 축소가 됩니다. [최소, 최대]처럼 확대 비율의 범위를 리스트로 전달할 수도 있습니다.

[22](Section0502.html#footnote-05-22-backlink)  역주  예를 들어 도로 표지판 같은 경우 수평으로 뒤집힌 글씨를 학습시키는 것은 도움이 되지 않습니다.

[23](Section0502.html#footnote-05-23-backlink)  역주 기본값인 ‘nearest’는 인접한 픽셀을 사용하고 ‘constant’는  cval  매개변수의 값을 사용합니다. 그 외 ‘reflect’와 ‘wrap’이 있습니다. 전체 매개변수에 대한 설명은 케라스 문서([https://bit.ly/2KxVKne](https://bit.ly/2KxVKne))를 참고하세요.

[24](Section0502.html#footnote-05-24-backlink)  역주  파이썬에서 튜플이나 리스트 2개를 더하면 하나의 튜플로 연결됩니다.  flow()  메서드는 배치 데이터를 기대하기 때문에 샘플 데이터에 배치 차원을 추가하여 4D 텐서로 만듭니다.

[25](Section0502.html#footnote-05-25-backlink)  역주 이 장에서는 합성곱에서 추출한 특성 맵을 사용하여 클래스를 분류한다는 의미로 합성곱 층 위에 놓인 완전 연결 층들을 완전 연결 분류기(densely connected classifier)라고 부릅니다.

[26](Section0502.html#footnote-05-26-backlink)  역주  테스트 세트도 증식되어서는 안 됩니다.  ImageDataGenerator에는 없지만 데이터 증식 방법 중 랜덤 크롭(crop)을 적용한다면 입력 데이터의 크기를 맞추기 위해 예외적으로 검증 세트와 테스트 세트도 크롭해야 합니다. 이때는 이미지의 가운데나 랜덤한 위치에서 한 번 크롭하여 검증 세트와 테스트 세트를 준비합니다.

[27](Section0503.html#footnote-05-27-backlink)  Karen Simonyan and Andrew Zisserman, “Very Deep Convolutional Networks for Large-Scale Image Recognition,” arXiv (2014), [https://arxiv.org/abs/1409.1556](https://arxiv.org/abs/1409.1556).

[28](Section0503.html#footnote-05-28-backlink)  역주  keras.applications  아래의 모듈들은 Keras-Applications 패키지의 알리아스입니다. 이 패키지는 Keras와 함께 자동으로 설치됩니다. 본문에 나열된 것 이외에도 다음 모델들이 포함되어 있습니다.

•  InceptionResNetV2(Christian Szegedy, et al. “Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning,” arXiv (2016),  [https://arxiv.org/abs/1602.07261](https://arxiv.org/abs/1602.07261)).

•  MobileNetV2(Mark Sandler, et al. “MobileNetV2: Inverted Residuals and Linear Bottlenecks,” arXiv (2018), [https://arxiv.org/abs/1801.04381](https://arxiv.org/abs/1801.04381)).

•  DenseNet(Gao Huang, et al. “Densely Connected Convolutional Networks,” arXiv (2016), [https://arxiv.org/abs/1608.06993](https://arxiv.org/abs/1608.06993)).

•  NASNet(Barret Zoph, et al. “Learning Transferable Architectures for Scalable Image Recognition,” arXiv (2017), [https://arxiv.org/abs/1707.07012](https://arxiv.org/abs/1707.07012)).

[29](Section0503.html#footnote-05-29-backlink)  역주  François Chollet, “Xception: Deep Learning with Depthwise Separable Convolutions,” arXiv (2016), [https://arxiv.org/abs/1610.02357](https://arxiv.org/abs/1610.02357).

[30](Section0503.html#footnote-05-30-backlink)  역주  Christian Szegedy, et al. “Rethinking the Inception Architecture for Computer Vision,” arXiv (2015), [https://arxiv.org/abs/1512.00567](https://arxiv.org/abs/1512.00567).

[31](Section0503.html#footnote-05-31-backlink)  역주  Kaiming He, et al. “Deep Residual Learning for Image Recognition,” arXiv (2015), [https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385).

[32](Section0503.html#footnote-05-32-backlink)  역주  VGG19는 합성곱 층 16개, 완전 연결 층 3개로 이루어져 있습니다. VGG16은 합성곱 층 13개, 완전 연결 층이 3개입니다.

[33](Section0503.html#footnote-05-33-backlink)  역주  Andrew G. Howard, et al. “MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications,” arXiv (2017), [https://arxiv.org/abs/1704.04861](https://arxiv.org/abs/1704.04861).

[34](Section0503.html#footnote-05-34-backlink)  역주  include_top이 기본값  True이면 합성곱 층 위에 완전 연결 층이 추가되기 때문에  input_shape이 원본 모델과 동일한  (224, 224, 3)이 되어야 합니다.

[35](Section0503.html#footnote-05-35-backlink)  역주  케라스에서 신경망을 위한 가장 상위 클래스인  Layer  클래스를 상속하여  keras.layers  아래의 층들이 구현됩니다. 또  Layer  클래스를 상속한  Network  클래스가 비순환 유향 그래프를 구현하고  Network  클래스를 상속한  Model  클래스는 신경망의 훈련 과정을 구현합니다. 따라서  Model  클래스를 상속한  Sequential  클래스는 층은 물론 다른 모델도 추가할 수 있습니다.

[36](Section0503.html#footnote-05-36-backlink)  역주  예를 들어  block1_conv1 층의 경우 윈도우 크기가 3×3, 입력 채널의 깊이가 3, 필터의 개수가 64개이므로 가중치 행렬의 크기는  (3, 3, 3, 64)가 됩니다. 편향은 필터마다 하나씩 필요하므로 (64,)의 크기를 가집니다. 모델의  trainable_weights  속성을 출력하면 전체 가중치 크기를 확인할 수 있습니다.

[37](Section0503.html#footnote-05-37-backlink)  역주 4.5.5절에서 설명했듯이 정확도를 직접 최적화할 수 없고 크로스엔트로피 같은 대리 손실 함수(surrogate loss function)를 사용하기 때문에 이런 현상이 발생할 수 있습니다.

[38](Section0504.html#footnote-05-38-backlink)  역주  데이터를 컬러 색상의 강도로 표현하는 그래프를 히트맵 그래프라고 합니다. 히트맵에 사용하는 전형적인 컬러맵(colormap)은 파란색(낮은 값), 녹색, 빨간색(높은 값)을 사용하는 제트(jet) 컬러맵입니다. 제트 컬러맵은 블랙홀처럼 밀도가 높은 천체의 회전축을 따라 이온화된 물질이 방출되는 제트 현상의 연구에서 유래된 것으로 알려져 있습니다. 코드 5-44에 있는  cv2.COLORMAP_JET가 제트 컬러맵을 의미합니다.

[39](Section0504.html#footnote-05-39-backlink)  역주 입력 데이터의 첫 번째 차원은 배치 차원입니다. 데이터가 하나뿐이더라도 입력 데이터의 차원을 맞추어야 하므로 첫 번째 차원을 추가합니다. 코드 5-12에서는 같은 작업에 reshape() 메서드를 사용했습니다.

[40](Section0504.html#footnote-05-40-backlink)  역주  임의의 실수인 층의 출력을 픽셀로 표현이 가능한 0~255 사이의 정수로 바꾸었습니다. 먼저 평균을 빼고 표준 편차로 나누어 표준 점수(standard score)로 바꿉니다. 그다음 표준 점수 2.0 이내의 값(약 95% 정도가 포함됩니다)들이 0~255 사이에 놓이도록 증폭시킨 후 클리핑했습니다.

[41](Section0504.html#footnote-05-41-backlink)  역주  경사 상승법은 손실 함수의 값이 커지는 방향으로 그래디언트를 업데이트하기 때문에 경사 하강법과 반대이지만, 학습 과정은 동일합니다. 이 절에서는 두 용어를 섞어 사용하는데 번역서에서는 혼동을 피하기 위해 경사 상승법으로 통일했습니다.

[42](Section0504.html#footnote-05-42-backlink)  역주 이런 기법을 그래디언트 클리핑(gradient clipping)이라고 합니다. L2 노름으로 나눈 그래디언트의 L2 노름은 1이 됩니다. 케라스의  keras.optimizers 모듈 아래에 있는 옵티마이저를 사용할 때는  clipnorm과  clipvalue  매개변수를 설정하여 자동으로 그래디언트 클리핑을 수행할 수 있습니다.  clipnorm  매개변수 값이 그래디언트의 L2 노름보다 클 경우 각 그래디언트의 L2 노름을  clipnorm  값으로 정규화합니다.  clipvalue  매개변수를 지정하면 그래디언트의 최대 절댓값은 clipvalue 값이 됩니다. 두 매개변수를 모두 설정하면  clipnorm이 먼저 적용되고  clipvalue가 적용됩니다.

[43](Section0504.html#footnote-05-43-backlink)  역주  경사 상승법을 사용하기 때문에  keras.optimizers  모듈 아래에 있는 옵티마이저를 사용할 수 없고, 직접 학습 단계를 구현해야 합니다.  keras.backend.function() 함수는 입력 값을 받아 지정된 출력 텐서들을 얻을 수 있는  keras.backend.Function  객체를 만들어 줍니다.

[44](Section0504.html#footnote-05-44-backlink)  역주  코드 5-31에서 했던 것과 유사합니다. 여기에서는 표준 점수의 5배수 이내에 있는 값(거의 100%가 포함됩니다)들을 0~255 사이로 압축했습니다.

[45](Section0504.html#footnote-05-45-backlink)  Ramprasaath R. Selvaraju et al., arXiv (2017),  [https://arxiv.org/abs/1610.02391](https://arxiv.org/abs/1610.02391).

[46](Section0504.html#footnote-05-46-backlink)  역주  VGG 모델은 카페(Caffe) 딥러닝 라이브러리에서 훈련되어 정규화 방식이 조금 다릅니다. 입력 데이터의 이미지 채널을 RGB에서 BGR로 바꾸고 ImageNet 데이터셋에서 구한 채널별 평균값 [103.939, 116.779, 123.68]을 뺍니다.

[47](Section0504.html#footnote-05-47-backlink)  역주  decode_predictions() 함수는 ImageNet 데이터셋에 대한 예측 결과에서  top  매개변수에 지정된 수만큼 최상위 항목을 반환해 줍니다.

[48](Section0504.html#footnote-05-48-backlink)  역주  matplotlib의 기본 컬러맵은  viridis로 노란색이 가장 높은 값을 나타냅니다.

[49](Section0504.html#footnote-05-49-backlink)  역주  인도 코끼리는 아프리카 코끼리보다 작은 귀를 가진 것이 특징입니다. 그림 5-36에서 아기 코끼리의 귀 부분이 붉게 표시되었습니다.
