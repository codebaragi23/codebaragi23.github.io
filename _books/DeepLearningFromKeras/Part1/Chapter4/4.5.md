---
title: 4.5 보편적인 머신 러닝 작업 흐름
---

이 절에서 머신 러닝 문제를 해결하기 위해 사용할 수 있는 보편적인 청사진을 제시하겠습니다. 이 청사진은 이 장에서 배운 문제 정의, 평가, 특성 공학, 과대적합의 개념과 연결되어 있습니다.

## 4.5.1  문제 정의와 데이터셋 수집

먼저 주어진 문제를 정의해야 합니다.

- 입력 데이터는 무엇인가요? 어떤 것을 예측하려고 하나요? 가용한 훈련 데이터가 있어야 어떤 것을 예측하도록 학습할 수 있습니다. 예를 들어 영화 리뷰와 감성 레이블이 태깅되어 있어야 영화 리뷰의 감성 분류를 학습할 수 있습니다. 이런 식으로 보통 가용 데이터의 유무는 이 단계에서 제한 요소가 됩니다(데이터를 수집할 비용이 없다면).
- 당면한 문제가 어떤 종류인가요? 이진 분류인가요? 다중 분류인가요? 스칼라 회귀인가요? 벡터 회귀인가요? 다중 레이블 다중 분류인가요? 아니면 군집, 생성 또는 강화 학습 같은 다른 문제인가요? 문제의 유형을 식별하면 모델의 구조와 손실 함수 등을 선택하는 데 도움이 됩니다.

입력과 출력이 무엇인지와 어떤 데이터를 사용할 것인지 알기 전까지는 다음 단계로 넘어갈 수 없습니다. 이 단계에서 가설을 세워야 합니다.

- 주어진 입력으로 출력을 예측할 수 있다고 가설을 세웁니다.
- 가용한 데이터에 입력과 출력 사이의 관계를 학습하는 데 충분한 정보가 있다고 가설을 세웁니다.

모델이 작동하기 전까지 이는 가설에 불과합니다. 검증될지 아닐지 기다려 보아야 합니다. 모든 문제가 해결되지는 않습니다. 입력 X와 타깃 Y의 샘플을 수집했다고 X에 Y를 예측하기에 충분한 정보가 있는 것은 아닙니다. 예를 들어 주식 시장의 최근 가격 변동 정보를 가지고 주가를 예측한다면 실패할 가능성이 높습니다. 과거 가격 정보에는 예측에 활용할 정보가 많지 않기 때문입니다.

풀기 어려운 종류의 문제는 시간에 따라 변하는 문제(nonstationary problem)입니다. 옷을 위한 추천 엔진을 구축한다고 가정합시다. 한 달치(8월)의 데이터로 훈련하고 겨울에 이 추천 엔진을 사용하려고 합니다. 여기서 문제는 사람들이 계절에 따라 구매하려는 옷의 종류가 바뀐다는 것입니다. 의류 구매는 몇 달에 걸쳐 보면 시간에 따라 바뀌어 유동적입니다. 시간에 따라 모델을 바꾸기 위해 어떻게 해야 할까요? 이런 경우에 최근의 데이터로 주기적으로 모델을 다시 훈련하거나 시간 분포에 맞게 데이터를 수집하여 시간에 따라 변하지 않는 문제로 바꿉니다. 의류 구매처럼 순환성이 있는 문제는 몇 년치의 데이터를 모으면 계절의 변화를 감지하는 데 충분할 것입니다. 1년 중 언제인지 기록한 시간도 모델에 입력해야 한다는 것을 잊지 마세요!

머신 러닝은 훈련 데이터에 있는 패턴을 기억하기 위해서만 사용한다는 것을 유념하세요. 이미 보았던 것만 인식할 수 있습니다. 미래를 예측하기 위해 과거 데이터에서 훈련한 머신 러닝을 사용하는 것은 미래가 과거처럼 움직인다고 가정한 것입니다. 사실 대부분 그렇지는 않습니다.

## 4.5.2 성공 지표 선택

어떤 것을 제어하려면 관측할 수 있어야 합니다. 성공하기 위해서는 성공은 무엇인가를 정의해야 합니다. 정확도일까요? 정밀도나 재현율일까요? 고객 재방문율일까요? 성공의 지표가 모델이 최적화할 손실 함수를 선택하는 기준이 됩니다. 비즈니스 성공처럼 고수준의 목표와 직접적으로 연결되어 있어야 합니다.[^1]

[^1]: 특히 군집 같은 비지도 학습에는 신뢰할 만한 측정 지표가 없습니다. 군집의 결과가 비즈니스에 기여한 정도를 측정하는 것이 좋은 방법입니다. 누군가가 고객을 성공적으로 클러스터링했다고 말한다면 어떻게 성공을 측정했는지 물어보는 것이 좋습니다.

클래스 분포가 균일한 분류 문제에서는 정확도와  ROC AUC가 일반적인 지표입니다. 클래스 분포가 균일하지 않은 문제에서는 정밀도와 재현율을 사용할 수 있습니다. 랭킹 문제나 다중 레이블 문제에는  평균 정밀도를 사용할 수 있습니다.[^2] 성공을 측정하기 위해 자신만의 지표를 정의하는 일은 일반적이지 않습니다. 머신 러닝의 다양한 성공 지표가 여러 가지 종류의 문제에 어떻게 관련되어 있는지 알고 싶다면 캐글([https://kaggle.com](https://kaggle.com))의 데이터 과학 경연 대회를 살펴보는 것이 도움이 됩니다. 캐글에서 굉장히 다양한 문제들과 측정 지표들을 볼 수 있습니다.

[^2]: ROC(Receiver Operating Characteristic curve)는 거짓양성비율(false positive rate)에 대한 재현율의 곡선이고, ROC AUC는 ROC 곡선의 아랫부분 면적입니다. 정밀도에 대한 재현율의 곡선을 정밀도-재현율 곡선이라고 하며, 평균 정밀도(average precision)는 이 곡선의 아랫부분 면적입니다. 사이킷런은 ROC AUC를 위한  roc_auc_score()  함수와 평균 정밀도를 위한  average_precision_score() 함수를 제공합니다. 머신 러닝 모델의 평가 방법에 대한 자세한 설명은 <파이썬 라이브러리를 활용한 머신러닝>(한빛미디어, 2017)의 5장을 참고하세요.

## 4.5.3  평가 방법 선택

목표를 정했다면 현재의 진척 상황을 평가할 방법을 정해야 합니다. 앞서 잘 알려진 세 가지의 평가 방식을 소개했습니다.

- 홀드아웃 검증 세트 분리: 데이터가 풍부할 때 사용합니다.
- K-겹 교차 검증: 홀드아웃 검증을 사용하기에 샘플의 수가 너무 적을 때 사용합니다.
- 반복 K-겹 교차 검증: 데이터가 적고 매우 정확한 모델 평가가 필요할 때 사용합니다.

이 중에 하나를 선택하면 됩니다. 대부분의 경우 첫 번째로 충분할 것입니다.[^3]

[^3]: K-겹 교차 검증은 얕은 학습 방법에서 자주 사용됩니다. 보통 딥러닝을 사용할 때는 데이터가 풍부한 상황이므로 홀드아웃 방법으로 대체할 수 있습니다. 대규모 딥러닝 모델은 훈련 비용이 너무 커서 교차 검증을 적용하기 어려울 때가 많습니다.

## 4.5.4  데이터 준비

무엇을 훈련할지와 무엇을 최적화할지, 그리고 어떻게 평가할지를 정했다면 거의 모델을 훈련시킬 준비가 되었습니다. 하지만 먼저 머신 러닝 모델에 주입할 데이터를 구성해야 합니다. 여기에서는 이 머신 러닝 모델을 심층 신경망이라고 가정합니다.

- 앞서 보았듯이 데이터는 텐서로 구성됩니다.
- 이 텐서에 있는 값은 일반적으로 작은 값으로 스케일 조정되어 있습니다. 예를 들어 [-1, 1]이나 [0, 1] 범위입니다.
- 특성마다 범위가 다르면(여러 종류의 값으로 이루어진 데이터라면) 정규화해야 합니다.
- 특성 공학을 수행할 수 있습니다. 특히 데이터가 적을 때입니다.

입력 데이터와 타깃 데이터의 텐서가 준비되면 모델을 훈련시킬 수 있습니다.

## 4.5.5  기본보다 나은 모델 훈련하기

이 단계의 목표는  통계적 검정력(statistical power)을 달성하는 것입니다. 즉 아주 단순한 모델보다 나은 수준의 작은 모델을 개발합니다. MNIST 숫자 이미지 분류 예에서는 0.1보다 높은 정확도를 내는 모델이 통계적 검정력을 가졌다고 말할 수 있습니다. IMDB 예에서는 0.5보다 높은 정확도를 갖는 것입니다.[^4]

[^4]: 검정력은 우리가 세운 가설이 참일 때 이를 채택할 확률을 말합니다. 여기에서는 적어도 데이터셋에 있는 클래스별 분포보다 모델의 정확도가 높아야 우리가 세운 가설이 옳다고 말할 수 있습니다.

통계적 검정력을 달성하는 것이 항상 가능하지는 않습니다. 여러 개의 타당성 있는 네트워크 구조를 시도해 보고 무작위로 예측하는 모델보다 낫지 않다면 입력 데이터에 존재하지 않는 것을 얻으려고 한다는 신호일 것입니다. 2개의 가설이 있다는 것을 기억하세요.

- 주어진 입력으로 출력을 예측할 수 있다고 가설을 세웁니다.
- 가용한 데이터에 입력과 출력 사이의 관계를 학습하는 데 충분한 정보가 있다고 가설을 세웁니다.

이 가설이 잘못된 것일 수 있습니다. 이때는 기획부터 다시 해야 합니다.

일이 잘 진행된다고 가정하면 첫 번째 모델을 만들기 위해 세 가지 중요한 선택을 해야 합니다.

- 마지막 층의 활성화 함수: 네트워크의 출력에 필요한 제한을 가합니다. 예를 들어 IMDB 분류 예는 마지막 층에 시그모이드 함수를 사용합니다. 회귀 예에서는 마지막 층에 활성화 함수를 사용하지 않습니다.
- 손실 함수: 풀려고 하는 문제의 종류에 적합해야 합니다. 예를 들어 IMDB 예제는  binary_crossentropy를 사용하고, 회귀 예제는  mse를 사용하는 식입니다.
- 최적화 설정: 어떤 옵티마이저를 사용하나요? 학습률은 얼마인가요? 대부분의 경우  rmsprop과 기본 학습률을 사용하는 것이 무난합니다.[^5]

[^5]: 자주 사용하는 옵티마이저 중에 ‘rmsprop’, ‘adam’은 기본 학습률이 0.001이고 ‘sgd’, ‘adagrad’는 0.01입니다.

손실 함수의 선택에 대해서 언급할 것은 주어진 문제의 성공 지표를 직접 최적화하는 것이 항상 가능하지 않다는 점입니다. 때로는 이 지표를 손실 함수로 바꿀 수 있는 방법이 없습니다. 무엇보다도 손실 함수는 주어진 미니 배치 데이터에서 계산 가능해야 하고(이상적으로는 손실 함수는 하나의 데이터 포인트에서도 계산 가능해야 합니다), 미분 가능해야 합니다(그렇지 않으면 역전파 알고리즘을 사용하여 네트워크를 훈련시킬 수 없습니다). 예를 들어 널리 사용되는 분류 지표인 ROC AUC는 직접 최적화될 수 없습니다.[^6] 그래서 분류 작업에는 크로스엔트로피처럼 ROC AUC를 대신할 지표를 최적화하는 것이 보통입니다. 일반적으로 크로스엔트로피가 낮을수록 ROC AUC가 높다고 기대할 수 있습니다.

[^6]: 0-1 손실이라고도 부르는 정확도를 비롯하여 ROC AUC 계산에 사용되는 거짓양성비율과 재현율 모두 예측이 맞은 개수와 틀린 개수를 헤아리는 방식을 사용합니다. 이런 방법들은 미분 가능한 함수가 아닙니다.

표 4-1에 자주 등장하는 문제 유형에 따라 선택할 수 있는 마지막 층의 활성화 함수와 손실 함수를 정리했습니다.

_표 4-1  모델에 맞는 마지막 층의 활성화 함수와 손실 함수 선택_

문제 유형

마지막 층의 활성화 함수

손실 함수

이진 분류

시그모이드

binary_crossentropy

단일 레이블 다중 분류

소프트맥스

categorical_crossentropy

다중 레이블 다중 분류

시그모이드

binary_crossentropy

임의 값에 대한 회귀

없음

mse

0과 1 사이 값에 대한 회귀

시그모이드

mse 또는 binary_crossentropy

## 4.5.6  몸집 키우기: 과대적합 모델 구축

통계적 검정력을 가진 모델을 얻었다면 이제 모델이 충분히 성능을 내는지 질문해 보아야 합니다. 주어진 문제를 적절히 모델링하기에 충분한 층과 파라미터가 있나요? 예를 들어 2개의 유닛을 가진 하나의 은닉 층으로 구성된 네트워크가 있다고 가정합시다. 이 네트워크가 MNIST 데이터셋에서 통계적 검정력을 가질 수 있지만 문제를 잘 해결하기에는 충분하지 않을 것입니다. 머신 러닝은 최적화와 일반화 사이의 줄다리기라는 점을 기억하세요. 과소적합과 과대적합 사이, 즉 과소용량과 과대용량의 경계에 적절히 위치한 모델이 이상적입니다. 이 경계가 어디에 위치하는지 찾기 위해서는 먼저 지나쳐 보아야 합니다.

얼마나 큰 모델을 만들어야 하는지 알기 위해서는 과대적합된 모델을 만들어야 합니다. 이는 아주 쉽습니다.

1. 층을 추가합니다.
2. 층의 크기를 키웁니다.
3. 더 많은 에포크 동안 훈련합니다.

관심 대상인 훈련과 검증 지표는 물론 항상 훈련 손실과 검증 손실을 모니터링하세요. 검증 데이터에서 모델 성능이 감소하기 시작했을 때 과대적합에 도달한 것입니다.

다음 단계에서 규제와 모델 튜닝을 시작하여 과소적합도 아니고 과대적합도 아닌 이상적인 모델에 가능한 가깝도록 만듭니다.

## 4.5.7  모델 규제와 하이퍼파라미터 튜닝

이 단계가 대부분의 시간을 차지합니다. 반복적으로 모델을 수정하고 훈련하고 검증 데이터에서 평가합니다(이때 테스트 데이터를 사용하지 않습니다). 그리고 다시 수정하고 가능한 좋은 모델을 얻을 때까지 반복합니다. 적용해 볼 것들은 다음과 같습니다.

- 드롭아웃을 추가합니다.
- 층을 추가하거나 제거해서 다른 구조를 시도해 봅니다.
- L1이나 L2 또는 두 가지 모두 추가합니다.
- 최적의 설정을 찾기 위해 하이퍼파라미터를 바꾸어 시도해 봅니다(층의 유닛 수나 옵티마이저의 학습률 등).
- 선택적으로 특성 공학을 시도해 봅니다. 새로운 특성을 추가하거나 유용하지 않을 것 같은 특성을 제거합니다.

다음 사항을 유념하세요. 검증 과정에서 얻은 피드백을 사용하여 모델을 튜닝할 때마다 검증 과정에 대한 정보를 모델에 누설하고 있다는 것입니다. 몇 번만 반복하는 것은 큰 문제가 되지 않습니다. 하지만 많이 반복하게 되면 결국 모델이 검증 과정에 과대적합될 것입니다(모델이 검증 데이터에서 전혀 훈련되지 않는데도 말입니다). 이는 검증 과정의 신뢰도를 감소시킵니다.

만족할 만한 모델 설정을 얻었다면 가용한 모든 데이터(훈련 데이터와 검증 데이터)를 사용해서 제품에 투입할 최종 모델을 훈련시킵니다. 그리고 마지막에 딱 한 번 테스트 세트에서 평가합니다. 테스트 세트의 성능이 검증 데이터에서 측정한 것보다 많이 나쁘다면, 검증 과정에 전혀 신뢰성이 없거나 모델의 하이퍼파라미터를 튜닝하는 동안 검증 데이터에 과대적합된 것입니다. 이런 경우에는 좀 더 신뢰할 만한 평가 방법으로 바꾸는 것이 좋습니다(반복 K-겹 교차 검증).
