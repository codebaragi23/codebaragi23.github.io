---
title: 2.6 요약
---

- **학습Learning**: 훈련 데이터 샘플과 그에 상응하는 타깃이 주어졌을 때 손실 함수를 최소화하는 모델 파라미터의 조합을 찾는 것
- 데이터 샘플과 타깃의 배치를 랜덤하게 뽑고 이 배치에서 손실에 대한 파라미터의 그래디언트를 계산함으로써 학습이 진행  
네트워크의 파라미터는 **그래디언트의 반대 방향**으로 조금씩(학습률에 의해 정의된 크기만큼) 움직임
- 전체 학습 과정은 신경망이 **미분 가능한 텐서 연산**으로 연결되어 있기 때문에 가능  
현재 파라미터와 배치 데이터를 그래디언트 값에 매핑해 주는 그래디언트 함수를 구성하기 위해 미분의 **연쇄 법칙**을 사용

이어지는 장에서 자주 보게 될 두 가지 핵심 개념은 **손실**과 **옵티마이저**입니다. 이 두 가지는 네트워크에 데이터를 주입하기 전에 정의되어야 합니다.
- 손실: 훈련하는 동안 최소화해야 할 양이므로 해결하려는 문제의 성공을 측정하는 데 사용
- 옵티마이저: 손실에 대한 그래디언트가 파라미터를 업데이트하는 정확한 방식을 정의  
e.g.) RMSProp 옵티마이저, 모멘텀을 사용한 SGD
