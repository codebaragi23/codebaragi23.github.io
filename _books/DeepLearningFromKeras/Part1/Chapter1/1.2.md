---
title: 1.2 딥러닝 이전-머신 러닝의 간략한 역사
---

전통적인 머신 러닝 방법에 대한 자세한 설명은 이 책의 범위를 넘어섭니다. 하지만 이들을 간단하게 소개하고 역사적 배경을 설명하겠습니다.


## 1.2.1 확률적 모델링

**확률적 모델링(probability modeling)** 은 통계학 이론을 데이터 분석에 응용한 것입니다. 초창기 머신 러닝 형태 중 하나이고, 현재에도 많이 사용됩니다. 가장 잘 알려진 알고리즘은 나이브 베이즈(Naive Bayes) 알고리즘입니다.

나이브 베이즈 알고리즘이란 입력 데이터의 특성이 모두 독립적이라고 가정하고 베이즈 정리(Bayes’ theorem)를 적용하는 머신 러닝 분류 알고리즘입니다.

이와 관련된 모델은 **로지스틱 회귀(logistic regression)** 입니다. (줄여서 logreg라고도 부르는 것 같습니다.) 이름은 회귀인데 회귀 알고리즘이 아닌 분류 알고리즘 입니다.[^1]

[^1]: 회귀는 연속적인 숫자(실수)를 예측하는 것이고 분류는 여러 클래스class 중 하나를 예측하는 것입니다. 3.6절에 주택 가격을 예측하 는 회귀 예제를 제외하고 이 책의 나머지는 대부분 분류에 대한 예제입니다.

데이터 과학자가 분류 작업에 대한 초기 감을 위해 첫 번째로 선택되는 알고리즘입니다.


## 1.2.2 초창기 신경망

초창기 신경망과 현재의 신경망에는 큰 차이가 있습니다.

1950년대에는 대규모 신경망에 대한 효율적인 학습 방법이 없었으나, 1980년대에 여러 사람들이 제각기 역전파 알고리즘을 발견하며 현재의 신경망까지 발전할 수 있었습니다.


## 1.2.3 커널 방법

커널 방법(Kernel method) 분류 알고리즘의 한 종류로 그 중에서는 서포트 **벡터 머신(Support Vector Machine, SVM)** 이 가장 유명합니다.[^2]

[^2]: SVM은 분류뿐만 아니라 회귀 문제에도 사용할 수 있습니다.

![나타낼 수 없음](https://dpzbhybb2pdcj.cloudfront.net/chollet/Figures/01fig10.jpg)  
_그림 1-10. 결정 경계_

SVM이 결정 경계를 찾는 과정은 두 단계입니다.

1. 결정 경계가 하나의 초평면hyperplane으로 표현될 수 있는 새로운 고차원 표현으로 데이터를 매핑합니다(그림 1-10과 같은 2차원 데이터라면 초평면은 직선이 됩니다).
2. 초평면과 각 클래스의 가장 가까운 데이터 포인트 사이의 거리가 최대가 되는 최선의 결정 경계(하나의 분할 초평면)를 찾습니다. 이 단계를 **마진 최대화**maximizing the margin라고 부릅니다. 이렇게 함으로써 결정 경계가 훈련 데이터셋 이외의 새로운 샘플에 잘 일반화되도록 도와줍니다.


## 1.2.4 결정 트리, 랜덤 포레스트, 그래디언트 부스팅 머신

**결정 트리(decision tree)** 는 플로우차트와 같은 구조를 가집니다. 특히 **랜덤 포레스트(Random Forest)** 알고리즘은 결정 트리 학습에 기초한 것으로 안정적이고 실전에 유용합니다.

![나타낼 수 없음](https://dpzbhybb2pdcj.cloudfront.net/chollet/Figures/01fig11.jpg)  
_그림 1-11. 결정 트리: 학습된 파라미터는 데이터에 관한 질문으로, 예를 들어 “데이터에 있는 두 번째 특성이 3.5보다 큰가?” 같은 질문이 될 수 있다_

**그래디언트 부스팅 머신(gradient boosting machine)** 은 후에 나온 기법으로, 이전 모델에서 놓친 데이터 포인트를 보완하는 새로운 모델을 반복적으로 훈련함으로써 머신 러닝 모델을 향상하는 방법인 그래디언트 부스팅을 사용합니다. 캐글 경연 대회에서 가장 많이 사용되는 기법입니다.


## 1.2.5 다시 신경망으로

2010년경부터 일부 사람들이 중요한 성과를 내며 신경망은 다시 주목을 받았습니다. 2015-2016년에 열린 컴퓨터비전 콘퍼런스에서는 어떤 형태로든 컨브넷(Convolution neural network - 영상 인식에 특화된 심층 신경)을 포함하지 않은 발표를 찾는 것이 어려울 정도로 합성곱 신경망은 이제 메인 알고리즘으로 자리잡았습니다.


## 1.2.6 딥러닝의 특징

딥러닝은 머신 러닝에서 가장 중요한 단계인 특성 공학을 자동화 한다는 점에서 매우 큰 장점을 가지고 있습니다. **특성공학(feature engineering)** 이란 초기 학습을 위한 데이터의 변환을 의미합니다. 전처리라고도 할 수 있습니다. 이런 딥러닝에서 데이터를 학습하는 방법에는 두가지 중요한 특징이 있습니다.

- 층을 거치며, 점진적으로 복잡한 표현이 만들어짐
- 점진적인 중간 표현이 공동으로 학습

이런 특징이 머신 러닝 접근 방법보다 딥러닝이 훨씬 성공하게 된 이유입니다.


## 1.2.7 머신 러닝의 최근 동향

동향을 알아보기 가장 좋은 방법은 사람들이 가장 많은 커뮤니티를 찾는 것입니다. 그렇기에 머신 러닝 알고리즘과 도구의 동향에 대한 정보를 얻는 좋은 방법은 캐글의 머신 러닝 경연을 살펴보는 것입니다.

2016-2017 캐글에는 그래디언트 부스팅 머신과 딥러닝의 두 가지 접근 방법이 주류를 이뤘다고 합니다.
